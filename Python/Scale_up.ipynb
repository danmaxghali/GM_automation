{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1cbff36-2512-4388-b29c-4eb306285231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure exists: 'C:\\Users\\Student\\OneDrive - Aston University\\Documents\\Biology\\Project\\Project_automation\\Python\\PDB_files\\pdb3d4s.ent' \n",
      "Structure exists: 'C:\\Users\\Student\\OneDrive - Aston University\\Documents\\Biology\\Project\\Project_automation\\Python\\PDB_files\\pdb3d4s.ent' \n",
      "[3d4s] STDOUT: 2025-03-03 17:55:08,180 | INFO : Extracted zip file to: output/\n",
      "\n",
      "2025-03-03 17:55:08,180 | INFO : Done in 2.70 seconds\n",
      "\n",
      "2025-03-03 17:55:08,180 | INFO : Extracted zip file to: output/\n",
      "2025-03-03 17:55:08,180 | INFO : Done in 2.70 seconds\n",
      "\n",
      "[3d4s] STDERR: \n",
      "[3d4s] STDOUT: 2025-03-03 17:57:02,732 | INFO : Extracted zip file to: output/\n",
      "\n",
      "2025-03-03 17:57:02,733 | INFO : Done in 2.59 seconds\n",
      "\n",
      "2025-03-03 17:57:02,732 | INFO : Extracted zip file to: output/\n",
      "2025-03-03 17:57:02,733 | INFO : Done in 2.59 seconds\n",
      "\n",
      "[3d4s] STDERR: \n"
     ]
    }
   ],
   "source": [
    "from Bio import PDB, SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import numpy as np\n",
    "import torch\n",
    "import pydssp\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Get PDB data\n",
    "pdb_codes = [\"3d4s\", \"3d4s\"]\n",
    "pdb_file = PDB.PDBList()\n",
    "for pdb_code in pdb_codes:\n",
    "    pdb_file.retrieve_pdb_file(pdb_code, file_format=\"pdb\", \n",
    "                               pdir=\"C:\\\\Users\\\\Student\\\\OneDrive - Aston University\\\\Documents\\\\Biology\\\\Project\\\\Project_automation\\\\Python\\\\PDB_files\")\n",
    "def three_to_one(resname):\n",
    "    aa_dict = {\n",
    "        \"ALA\": \"A\", \"ARG\": \"R\", \"ASN\": \"N\", \"ASP\": \"D\", \"CYS\": \"C\",\n",
    "        \"GLN\": \"Q\", \"GLU\": \"E\", \"GLY\": \"G\", \"HIS\": \"H\", \"ILE\": \"I\",\n",
    "        \"LEU\": \"L\", \"LYS\": \"K\", \"MET\": \"M\", \"PHE\": \"F\", \"PRO\": \"P\",\n",
    "        \"SER\": \"S\", \"THR\": \"T\", \"TRP\": \"W\", \"TYR\": \"Y\", \"VAL\": \"V\"\n",
    "    }\n",
    "    return aa_dict.get(resname, \"X\")  # Return 'X' for unknown residues\n",
    "\n",
    "\n",
    "def extract_pdb_fasta(pdb_filepath, chain_id, output_fasta):\n",
    "    parser = PDB.PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(pdb_code, pdb_filepath)\n",
    "\n",
    "    sequence = []\n",
    "    observed_residues = []\n",
    "    \n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            if chain.id == chain_id:  # Only process the target chain\n",
    "                for residue in chain.get_residues():\n",
    "                    if PDB.is_aa(residue):\n",
    "                        sequence.append(three_to_one(residue.get_resname()))\n",
    "                        observed_residues.append(residue.id[1])  # Keep track of numbering\n",
    "\n",
    "    fasta_seq = SeqRecord(Seq(\"\".join(sequence)), id=f\"{pdb_filepath}_{chain_id}\", description=\"\")\n",
    "    SeqIO.write(fasta_seq, output_fasta, \"fasta\")\n",
    "\n",
    "    return observed_residues  # Return numbering for later alignment\n",
    "\n",
    "chain_id = \"A\"\n",
    "all_observed_residues = {}\n",
    "\n",
    "for pdb_code in pdb_codes:\n",
    "    pdb_filepath = f\"C:\\\\Users\\\\Student\\\\OneDrive - Aston University\\\\Documents\\\\Biology\\\\Project\\\\Project_automation\\\\Python\\\\PDB_files\\\\pdb{pdb_code}.ent\"\n",
    "    fasta_filepath = f\"C:\\\\Users\\\\Student\\\\OneDrive - Aston University\\\\Documents\\\\Biology\\\\Project\\\\Project_automation\\\\Python\\\\Fasta_files\\\\{pdb_code}.fasta\"\n",
    "\n",
    "    observed_residues = extract_pdb_fasta(pdb_filepath, chain_id, fasta_filepath)\n",
    "    all_observed_residues[pdb_code] = observed_residues  # Store results\n",
    "\n",
    "#    print(f\"PDB: {pdb_code}, Extracted residues: {observed_residues}\")\n",
    "\n",
    "# Attempting to use DeepTMHMM through the terminal but accessing that through python\n",
    "\n",
    "\n",
    "def run_deeptmhmm(pdb_code, fasta_filepath):\n",
    "    results_dir = f\"C:\\\\Users\\\\Student\\\\OneDrive - Aston University\\\\Documents\\\\Biology\\\\Project\\\\Project_automation\\\\Python\\\\DeepTMHMM_results\\\\{pdb_code}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Run DeepTMHMM within the results directory\n",
    "    process = subprocess.Popen(\n",
    "        [\"biolib\", \"run\", \"DTU/DeepTMHMM\", \"--fasta\", fasta_filepath],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "        cwd=results_dir \n",
    "    )\n",
    "    \n",
    "    stdout, stderr = process.communicate() \n",
    "    print(f\"[{pdb_code}] STDOUT:\", stdout)\n",
    "    print(f\"[{pdb_code}] STDERR:\", stderr)\n",
    "\n",
    "for pdb_code in pdb_codes:\n",
    "    fasta_filepath = f\"C:\\\\Users\\\\Student\\\\OneDrive - Aston University\\\\Documents\\\\Biology\\\\Project\\\\Project_automation\\\\Python\\\\Fasta_files\\\\{pdb_code}.fasta\"\n",
    "    run_deeptmhmm(pdb_code, fasta_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc0ddc88-afbb-474e-8bbb-eb8cf83aaae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 28), (35, 63), (70, 104), (115, 140), (165, 197), (363, 394), (401, 424)]\n",
      "[(1, 28), (35, 63), (70, 104), (115, 140), (165, 197), (363, 394), (401, 424)]\n",
      "{'3D4S': {'A': [32, 59, 94, 66, 101, 135, 171, 146, 196, 228, 297, 266, 304, 327]}}\n"
     ]
    }
   ],
   "source": [
    "tmh_data = {}\n",
    "pdb_data = {}\n",
    "\n",
    "# Align output ranges with actual observed residues\n",
    "for pdb_code in pdb_codes:\n",
    "    tmh_ranges = []\n",
    "    tmh_result_file = f\"C:\\\\Users\\\\Student\\\\OneDrive - Aston University\\\\Documents\\\\Biology\\\\Project\\\\Project_automation\\\\Python\\\\DeepTMHMM_results\\\\{pdb_code}\\\\biolib_results\\\\TMRs.gff3\"\n",
    "    \n",
    "    with open(tmh_result_file) as file:\n",
    "        for line in file:\n",
    "            if \"TMhelix\" in line:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                start, end = int(parts[2]), int(parts[3])\n",
    "                tmh_ranges.append((start, end))\n",
    "    \n",
    "    # Use DSSP\n",
    "    parser = PDB.PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(pdb_code, pdb_filepath)\n",
    "    \n",
    "    # Select the first structure in the file and the A chain\n",
    "    chain = structure[0]['A']\n",
    "    \n",
    "    # Retrieve coordinates\n",
    "    coordinates = []\n",
    "    for residue in chain:\n",
    "        if PDB.is_aa(residue):\n",
    "            res_name = residue.get_resname()\n",
    "            for atom in residue:\n",
    "                if atom.get_name() in ['N', 'CA', 'C', 'O']:\n",
    "                    coordinates.append(atom.coord)\n",
    "    \n",
    "    # Prepare eliments of pytorch tensor\n",
    "    L = sum(1 for residue in chain if PDB.is_aa(residue))\n",
    "    atoms = 4\n",
    "    xyz = 3\n",
    "    \n",
    "    # Make coordinates into array first to increase efficiency\n",
    "    coord_array = np.array(coordinates)\n",
    "    \n",
    "    # Create tensor\n",
    "    coord_tensor = torch.tensor(coord_array, dtype=torch.float32).reshape([L, atoms, xyz])\n",
    "    \n",
    "    # Use pydssp to get secondary structure\n",
    "    ss_data = pydssp.assign(coord_tensor, out_type='c3')\n",
    "\n",
    "    def extend_tmh_ranges(tmh_ranges, ss_data, max_extend=9):\n",
    "        extended_tmh_ranges = []\n",
    "    \n",
    "        for start, end in tmh_ranges:\n",
    "            # Extend start position backwards if residues are consecutive 'H'\n",
    "            extended_start = start\n",
    "            for i in range(1, max_extend + 1):\n",
    "                prev_res = start - i\n",
    "                if prev_res >= 0 and ss_data[prev_res] == \"H\":  # Ensure valid index\n",
    "                    extended_start = prev_res\n",
    "                else:\n",
    "                    break  # Stop if a non-'H' is encountered\n",
    "    \n",
    "            # Extend end position forwards if residues are consecutive 'H'\n",
    "            extended_end = end\n",
    "            for i in range(1, max_extend + 1):\n",
    "                next_res = end + i\n",
    "                if next_res < len(ss_data) and ss_data[next_res] == \"H\":  # Ensure valid index\n",
    "                    extended_end = next_res\n",
    "                else:\n",
    "                    break  # Stop if a non-'H' is encountered\n",
    "    \n",
    "            extended_tmh_ranges.append((extended_start, extended_end))\n",
    "    \n",
    "    \n",
    "        return extended_tmh_ranges\n",
    "    \n",
    "    extended_tmh_ranges = extend_tmh_ranges(tmh_ranges, ss_data)\n",
    "    print(extended_tmh_ranges)\n",
    "\n",
    "    # Convert TMH positions to actual PDB residue numbers as pairs\n",
    "    tmh_extended_pairs = [\n",
    "        (observed_residues[start - 1], observed_residues[end - 1]) for start, end in extended_tmh_ranges\n",
    "    ]\n",
    "\n",
    "    def reorder_gpcr_tmh_ends(tmh_extended_pairs):\n",
    "        pattern = [\"extra\", \"intra\", \"intra\", \"extra\", \"extra\", \"intra\", \"intra\", \n",
    "                   \"extra\", \"extra\", \"intra\", \"intra\", \"extra\", \"extra\", \"intra\"]\n",
    "    \n",
    "        reordered = []\n",
    "        for i, label in enumerate(pattern):\n",
    "            if label == \"extra\":\n",
    "                reordered.append(tmh_extended_pairs[i // 2][0])  # Take start residue\n",
    "            else:  # \"intra\"\n",
    "                reordered.append(tmh_extended_pairs[i // 2][1])  # Take end residue\n",
    "    \n",
    "        return reordered\n",
    "    \n",
    "    flattened_tmh = reorder_gpcr_tmh_ends(tmh_extended_pairs)\n",
    "    \n",
    "    pdb_data[pdb_code.upper()] = {\"A\": flattened_tmh}\n",
    "\n",
    "\n",
    "print(pdb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d810a1-fe1f-4b0b-a166-9126c43a1a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
